{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931018b7",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cde7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #data frames (for storing data)\n",
    "import numpy as np #scientific computing\n",
    "import itertools\n",
    "\n",
    "#matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.ticker as mtick #for percentage ticks\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "\n",
    "# Rebalancing data \n",
    "from imblearn.over_sampling import SMOTE # Upsampling the minority class\n",
    "from imblearn.pipeline import Pipeline, make_pipeline \n",
    "\n",
    "# Classification import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model selection \n",
    "from sklearn.model_selection import train_test_split #Data split function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Model performance evaluation\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Plotting outlier\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649944cc",
   "metadata": {},
   "source": [
    "# 1. Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76285ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('marketing_data.csv')\n",
    "data.dropna()\n",
    "data.head(10).style #add .style to show all columns (otherwise some columns will be hidden with \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c311b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa59f09",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee18a8",
   "metadata": {},
   "source": [
    "## 2.1 Check NULL (missing) values and abnormal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56053d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.isnull().sum(), columns=['#Null values']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dc963",
   "metadata": {},
   "source": [
    "We observe \n",
    "- the column \" Income\" show some missing values (all variables show 1100 entries)\n",
    "- The column name ' Income ' has extra space so we need to strip it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af67a2",
   "metadata": {},
   "source": [
    "#### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip extra space in the column name \n",
    "data = data.rename(columns=lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the '$' sign from the Income and converting the dtype from 'object' to 'float'\n",
    "def income_convert(x):\n",
    "    try: \n",
    "        return float(x.split('$')[1].split('.')[0].replace(',',''))\n",
    "    except AttributeError: # as there are some missing values \n",
    "        return np.NaN\n",
    "    \n",
    "data['Income'] =  data['Income'].apply(income_convert) \n",
    "data['Income']= data['Income'].fillna(data['Income'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84cc20",
   "metadata": {},
   "source": [
    "#### Marital Status and Education "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa87ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Marital_Status'].unique())\n",
    "print(data['Education'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7cb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Marital status, the attribute \"YOLO\", \"ABSURD\" should be considered the same as \"single\"\n",
    "data.Marital_Status.replace({'Alone':'Single','YOLO':'Single','Absurd':'Single'}, inplace = True)\n",
    "# In education level, the value '2n Cycle' is technically euivalent to 'Master'\n",
    "data.Education.replace({'2n Cycle':'Master'}, inplace = True)\n",
    "print(data.Marital_Status.unique())\n",
    "print(data.Education.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de213c53",
   "metadata": {},
   "source": [
    "#### Transform Year_Birth to Age and Dt_Customer to Enrollment duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the year_birth into age \n",
    "from datetime import date\n",
    "Age = date.today().year - data['Year_Birth']\n",
    "data.insert(1, 'Age', Age,)\n",
    "data = data.drop(columns=['ID','Year_Birth'])\n",
    "\n",
    "# Transform the Dt_customer into enrollment duration\n",
    "dtime = pd.to_datetime(data['Dt_Customer'])\n",
    "Enroll_duration = date.today().year - dtime.dt.year\n",
    "data.insert(7, 'Enrollment_duration', Enroll_duration)\n",
    "data = data.drop(columns=['Dt_Customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc1ce6",
   "metadata": {},
   "source": [
    "## 2.2 Check outliers  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb5b59",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f82984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a box plot\n",
    "\n",
    "fig_age = px.box(data, y= 'Age')\n",
    "\n",
    "fig_age.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f443ba",
   "metadata": {},
   "source": [
    "We have notice that there are 3 people at age 122, 123, and 129, which is quite impossible. Therefore, we can conclude that there are some mistakes in this data collection. In this situation, we decide to either remove that observations for those people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1365e48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[data['Age'] <= 85]\n",
    "data['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e3333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a box plot\n",
    "fig_income = px.box(data, y = 'Income')\n",
    "fig_income.update_layout(width = 600, height = 400)\n",
    "fig_income.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d19e0",
   "metadata": {},
   "source": [
    "According to the box plot, the income has three outliers, so we can replace them with the median of the Income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Income'] > 162397, 'Income'] = int(data['Income'].median())\n",
    "print(data['Income'].max())\n",
    "print(data['Income'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26132e4e",
   "metadata": {},
   "source": [
    "## 2.3 Some descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21331fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab55190",
   "metadata": {},
   "source": [
    "# 3. Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bf774",
   "metadata": {},
   "source": [
    "## 3.1 Response vs non-response situation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reponse vs. non-response \n",
    "#c = ['#0E4C92', '#daf0ff']\n",
    "c = ['#0E4C92', '#77C6FC']\n",
    "keys, counts = np.unique(data.Response, return_counts=True)\n",
    "counts_norm = counts/counts.sum()\n",
    "fig = plt.figure(figsize=(3, 5)) #specify figure size\n",
    "ax1 = plt.bar(['Data'], [counts_norm[0]], label='no response', color=c[0])\n",
    "ax1 = plt.bar(['Data'], [counts_norm[1]], bottom=counts_norm[0], label='response', color=c[1])\n",
    "ax1 = plt.legend(bbox_to_anchor=(1, 1))\n",
    "ax1 = plt.ylabel('frequency')\n",
    "ax1 = plt.text(['Data'],counts_norm[0]/2, '{}%'.format((counts_norm[0]*100).round(1)), color = 'white', fontweight = 'semibold')\n",
    "ax1 = plt.text(['Data'],(counts_norm[1]/2)+counts_norm[0], '{}%'.format((counts_norm[1]*100).round(1)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0645090",
   "metadata": {},
   "source": [
    "We observe that the non-response cases account for about 85.1% of all observations. This imbalanced distribution of the response variable (response) occurs in many real-life Data Science problems and requires careful consideration when designing a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8965d",
   "metadata": {},
   "source": [
    "## 3.2 Response by some important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef013820",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_response = data.Response[data['Response']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df217036",
   "metadata": {},
   "source": [
    "#### Reponse by education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = pd.crosstab(data.Education, y_response).plot(kind='bar', color=c)\n",
    "plt.title('Response by Education')\n",
    "plt.xlabel('Education')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c96c1",
   "metadata": {},
   "source": [
    "#### Reponse by Maritial_Status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f50440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = pd.crosstab(data.Marital_Status, y_response).plot(kind='bar', color=c)\n",
    "plt.title('Response by Marital Status')\n",
    "plt.xlabel('Marital Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b37c62",
   "metadata": {},
   "source": [
    "#### Resopnse by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d030ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = pd.crosstab(data.Country, y_response).plot(kind='bar', color=c)\n",
    "plt.title('Response by Country')\n",
    "plt.xlabel('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(25,25))\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acc606",
   "metadata": {},
   "source": [
    "## 4. Data cleaning & Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95aeb05",
   "metadata": {},
   "source": [
    "#### 4.1 Remove variables that have no explanatory power or have beend stranformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e63138",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Age', 'Kidhome', 'Teenhome', 'Recency', 'NumWebVisitsMonth', 'Complain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97a97f",
   "metadata": {},
   "source": [
    "#### 4.2 Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=[\"Education\", 'Marital_Status', 'Country'], drop_first = True) #we add a prefix for easier identification\n",
    "data.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3edd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbb43c",
   "metadata": {},
   "source": [
    "## 5. Data split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a73cb8",
   "metadata": {},
   "source": [
    "To simulate this, we split our dataset into two subsets: training and testing. We use the training partition to build the model and the testing partition to evaluate the model performance.\n",
    "\n",
    "We split the data 70:30 into a training (data_train) and a testing (data_test) partition. Furthermore, we split the dataset into a feature matrix X (all columns, except the target fraudulent column) and a label vector y (only the fraudulent column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77098bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.loc[:, data.columns != 'Response'], data['Response'] #define feature matrix X and labels y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12345) #split data 70:30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35746232",
   "metadata": {},
   "source": [
    "We visualize the split to ensure that the distribution of fraudulent to non-fraudulent cases matches the distribution in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca248f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train_x:',X_train.shape)\n",
    "print('Train_y:',y_train.shape)\n",
    "print('Test_x:',X_test.shape)\n",
    "print('Test_y:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b5a3d",
   "metadata": {},
   "source": [
    "##  6. Rebalancing using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority', random_state = 0)\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train) #ONLY APPLIED TO TRAINING!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff799f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = y_train.value_counts() / len(y_train) #normalize absolute count values for plotting\n",
    "test_dist = y_test.value_counts() / len(y_test)\n",
    "data_dist = y.value_counts() / len(y)\n",
    "smote_dist = pd.Series(y_sm).value_counts() / len(pd.Series(y_sm))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(['X_train (SMOTE)','Test','Train','Data'], [smote_dist[0], test_dist[0], train_dist[0], data_dist[0]], color=c[0], label='0 (no)')\n",
    "ax.barh(['X_train (SMOTE)','Test','Train','Data'], [smote_dist[1], test_dist[1], train_dist[1], data_dist[1]], left=[smote_dist[0], test_dist[0], train_dist[0], data_dist[0]], color=c[1], label='1 (yes)')\n",
    "ax.set_title('Split visualization', size = 15)\n",
    "ax.legend(loc='upper left')\n",
    "plt.xlabel('Proportion')\n",
    "plt.ylabel('Partition')\n",
    "\n",
    "#plot bar values\n",
    "for part, a, b in zip(['X_train (SMOTE)', 'Test', 'Train','Data'], [smote_dist[0], test_dist[0], train_dist[0], data_dist[0]], [smote_dist[1], test_dist[1], train_dist[1], data_dist[1]]):\n",
    "    plt.text(a/2, part, str(np.round(a, 2)), color = 'white', fontweight = 'semibold')\n",
    "    plt.text(b/2+a, part, str(np.round(b, 2)), fontweight = 'medium');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388c613",
   "metadata": {},
   "source": [
    "# 7. Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7572ec",
   "metadata": {},
   "source": [
    "## 7.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef48e5",
   "metadata": {},
   "source": [
    "### 7.1.1 Build model with balanced data (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a184445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression()\n",
    "pipeline_LR= make_pipeline(SMOTE(random_state = 0), model_LR)\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits= 5, random_state = 0 , shuffle = True)\n",
    "parameters = {'C':[0.8,0.9,1,1.1,1.2],'random_state':[42], 'solver':['liblinear']} \n",
    "newLR_params = {'logisticregression__' + key: parameters[key] for key in parameters}\n",
    "model_LR_leGrid = GridSearchCV(pipeline_LR, param_grid= newLR_params, cv=cross_validation, scoring = 'accuracy', error_score=0)\n",
    "model_LR_leGrid.fit(X_train, y_train) #define Logistic Reg, ression classifier\n",
    "print(\"Best score: \", (model_LR_leGrid.best_score_*100).round(2))\n",
    "print(\"The best parameters:\", model_LR_leGrid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fbf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model with balanced data \n",
    "lr_SMOTE = LogisticRegression(solver='liblinear', random_state= 42, C = 1.1)\n",
    "lr_SMOTE.fit(X_sm,y_sm)\n",
    "lrSMOTE_pred = lr_SMOTE.predict(X_test)\n",
    "print('SMOTE Training set accuracy: {:.2%}'.format(lr_SMOTE.score(X_train, y_train)))\n",
    "print('SMOTE Test set accuracy: {:.2%}'.format(lr_SMOTE.score(X_test, y_test)))\n",
    "print('Test error:', (log_loss(y_test, lrSMOTE_pred)).round(3))\n",
    "print()\n",
    "\n",
    "# LR model with imblanced data \n",
    "# LR model with imbalanced data \n",
    "lr_UB = LogisticRegression(solver='liblinear', random_state= 42, C = 1)\n",
    "lr_UB.fit(X_train, y_train)\n",
    "lrUB_pred = lr_UB.predict(X_test)\n",
    "print('Unbalanced Training set accuracy: {:.2%}'.format(lr_UB.score(X_train, y_train)))\n",
    "print('Unbalanced Test set accuracy: {:.2%}'.format(lr_UB.score(X_test, y_test)))\n",
    "print('Test error:', (log_loss(y_test, lrUB_pred)).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f5bf9",
   "metadata": {},
   "source": [
    "## 7.2 Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149a26f",
   "metadata": {},
   "source": [
    "### 7.1.1 Gridsearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee323e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier()\n",
    "parameters = {'criterion' : ['gini', 'entropy'],'max_depth':[3,4,5,6], 'random_state': [13,42]}\n",
    "pipeline_rfc= make_pipeline(SMOTE(random_state = 0), model_tree)\n",
    "#print(pipeline)\n",
    "#print(model_rfc.get_params().keys())\n",
    "cross_validation = StratifiedKFold(n_splits = 5, random_state = 0 , shuffle = True)\n",
    "newLR_params = {'decisiontreeclassifier__' + key: parameters[key] for key in parameters}\n",
    "model_tree_legrid = GridSearchCV(pipeline_rfc, param_grid= newLR_params, cv=cross_validation, scoring = 'accuracy', error_score=0)\n",
    "model_tree_legrid.fit(X, y) #define Logistic Reg, ression classifier\n",
    "print('Decision Tree Classifier Cross validation score:', (model_tree_legrid.best_score_*100).round(2))\n",
    "print(model_tree_legrid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb532d90",
   "metadata": {},
   "source": [
    "### 7.2.1 Build the model and train it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93126839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree model with balanced data \n",
    "tree_SMOTE = DecisionTreeClassifier( criterion = 'gini', max_depth = 6, random_state = 42)\n",
    "tree_SMOTE.fit(X_sm,y_sm)\n",
    "treeSMOTE_pred = tree_SMOTE.predict(X_test)\n",
    "print('SMOTE Training set accuracy: {:.2%}'.format(tree_SMOTE.score(X_train, y_train)))\n",
    "print('SMOTE Test set accuracy: {:.2%}'.format(tree_SMOTE.score(X_test, y_test)))\n",
    "print('Test error:', (log_loss(y_test, treeSMOTE_pred)).round(3))\n",
    "print()\n",
    "\n",
    "# Decision tree model with imbalanced data\n",
    "tree_UB = DecisionTreeClassifier( criterion = 'gini', max_depth = 6, random_state = 42)\n",
    "tree_UB.fit(X_train, y_train)\n",
    "treeUB_pred = tree_UB.predict(X_test)\n",
    "print('Unbalanced Training set accuracy: {:.2%}'.format(tree_UB.score(X_train, y_train)))\n",
    "print('Unbalanced Test set accuracy: {:.2%}'.format(tree_UB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a2e01",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c16a7",
   "metadata": {},
   "source": [
    "In this project, we will use the following evaluation metrics:\n",
    "  - Confusion matrix\n",
    "  - Precision, recal, F-measure and support\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06477fc6",
   "metadata": {},
   "source": [
    "### 7.1 Confustion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_SMOTE_cf = confusion_matrix(y_test, lrSMOTE_pred)\n",
    "lr_UB_cf = confusion_matrix(y_test, lrUB_pred)\n",
    "tree_SMOTE_cf = confusion_matrix(y_test, treeSMOTE_pred)\n",
    "tree_UB_cf = confusion_matrix(y_test, treeUB_pred)\n",
    "\n",
    "# Visualize the confusiuon matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot()\n",
    "\n",
    "ax1= plt.subplot(2,2,1)\n",
    "sns.heatmap(lr_UB_cf, annot=True, fmt='g', ax=ax1, cmap=\"Blues\")\n",
    "ax1.set_xlabel('Predicted labels')\n",
    "ax1.set_ylabel('True labels')\n",
    "ax1.set_title('Logistic Regression Unbalanced Model',fontsize=15)\n",
    "\n",
    "ax2= plt.subplot(2,2,2)\n",
    "sns.heatmap(lr_SMOTE_cf, annot=True, fmt='g', ax=ax2, cmap=\"Blues\")\n",
    "ax2.set_xlabel('Predicted labels')\n",
    "ax2.set_ylabel('True labels')\n",
    "ax2.set_title('Logistic Regression SMOTE Model',fontsize=15)\n",
    "\n",
    "ax3= plt.subplot(223)\n",
    "sns.heatmap(tree_UB_cf, annot=True, fmt='g', ax=ax3, cmap=\"Blues\")\n",
    "ax3.set_xlabel('Predicted labels')\n",
    "ax3.set_ylabel('True labels')\n",
    "ax3.set_title('Decision Tree Unbalanced Model',fontsize=15)\n",
    "\n",
    "ax4= plt.subplot(224)\n",
    "sns.heatmap(tree_SMOTE_cf, annot=True, fmt='g', ax=ax4, cmap=\"Blues\")\n",
    "ax4.set_xlabel('Predicted labels')\n",
    "ax4.set_ylabel('True labels')\n",
    "ax4.set_title('Decision Tree SMOTE Model',fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe84c6",
   "metadata": {},
   "source": [
    "## 7.2 Precision, Recall, F-measure and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For balanced data \n",
    "from sklearn.metrics import classification_report\n",
    "print('Logistic Regression SMOTE data\\n\\n', classification_report(y_test, lrSMOTE_pred))\n",
    "print('Logistic Regression unbalanced data\\n\\n', classification_report(y_test, lrUB_pred))\n",
    "print('Decision Tree SMOTE data\\n\\n', classification_report(y_test, treeSMOTE_pred))\n",
    "print('Decision Tree unbalanced data\\n\\n', classification_report(y_test, treeUB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c8575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
